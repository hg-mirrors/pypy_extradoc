NEW TASKS
---------

- look at assembler-assembler calls again: if the inner function is
  traced after the outer one, the call is slow.  DONE

- have benchmarks for jit compile time and jit memory usage

- generators are not really fast.  DONE, with the only restriction
  that the code in generators is never inlined into some caller.

- think again about perfect specialization. Check if we loose anything
  if we turn it off. Another approach to specialization: specialize things
  in locals even if they're not referenced (that will solve bridges using
  new local variables, which I think is pretty common). Specialize things
  that are never changed, but read from (an into which is a loop constant
  will stay as a getfield).

- kill GUARD_(NO)_EXCEPTION; replace that by LAST_EXC_VALUE to load the
  current exception from the struct in memory, followed by a regular
  GUARD_CLASS.  (Armin: Look like a simplification, but it's a bit messy too)

- write a document that says what you cannot expect the jit to optimize.
  E.g. http://paste.pocoo.org/show/181319/ with B being old-style and
  C being new-style, or vice-versa.

- maybe refactor a bit the x86 backend, particularly the register
  allocation

- work more on visualization tools for traces or any profiler (unusable outside
  the core group)

- think about having different bytecode for "xyz %s" % stuff when left side
  is a compile time constant (and call unrolled version of string formatting
  loop in this case).

- generators are still fairly inefficient. We get a lot of:
  i = ptr_eq(frame, some_other_frame)
  guard_value(i, 0)
  every second instruction.

  there is also manipulating of valuestackdepth and such.

- consider how much old style classes in stdlib hurt us.

OPTIMIZATIONS
-------------

Things we can do mostly by editing optimizeopt.py:

- getfields which result is never used never get removed (probably cause -
  they used to be as livevars in removed guards). also getfields which result
  is only used as a livevar in a guard should be removed and encoded in
  the guard recovert code (only if we are sure that the stored field cannot
  change)

- if we move a promotion up the chain, some arguments don't get replaced
  with constants (those between current and previous locations). So we get
  like

  guard_value(p3, ConstPtr(X))
  getfield_gc(p3, descr)
  getfield_gc(ConstPtr(X), descr)

  maybe we should move promote even higher, before the first use and we
  could possibly remove more stuff?


PYTHON EXAMPLES
---------------

Extracted from some real-life Python programs, examples that don't give
nice code at all so far:

- string manipulation: s[n], s[-n], s[i:j], most operations on single
  chars, building a big string with repeated "s += t", "a,b=s.split()",
  etc.

- http://paste.pocoo.org/show/188520/
  this will compile new assembler path for each new type, even though that's
  overspecialization since in this particular case it's not relevant.
  This is treated as a megamorphic call (promotion of w_self in typeobject.py)
  while in fact it is not.

- guard_true(frame.is_being_profiled) all over the place

- xxx (find more examples :-)

BACKEND TASKS
-------------

Look into avoiding double load of memory into register on 64bit.
In case we want to first read a value, increment it and store (for example),
we end up with double load of memory into register. Like:

movabs 0xsomemem,r11
mov    (r11), r10
add    0x1, r10
movabs 0xsomemem,r11
mov    r10, (r11)

(second movabs could have been avoided)

LATER (maybe) TASKS
-------------------

- think out looking into functions or not, based on arguments,
  for example contains__Tuple should be unrolled if tuple is of constant
  length. HARD, blocked by the fact that we don't know constants soon enough
  Also, an unrolled loop means several copies of the guards, which may
  fail independently, leading to an exponential number of bridges

- out-of-line guards (when an external change would invalidate existing
  pieces of assembler)

- merge tails of loops-and-bridges?
