TASKS
-----

- inlining on the Python level (see discussion)
- streamline calls
- stability!

- upgrade python on wyvern
- improve test running, compile only once
- sort out a benchmark infrastructure. graphs!!!

- nightly run of checks on output of pypy-c-jit: we need tests for
  pypy-jit behaviour that explicitely check whether the loops make
  sense

- the tragedy of the skipped tests
- keep test coverage in check

- make x86 not recompile everything
   - think about code memory management

- compare backend vs gcc quality

- asmgcc: support callbacks (threads?)

- update things in metainterp/doc

Python interpreter:
- make shared dicts support shadowtracking
- make shared dicts revert to string dicts less often
- don't look for the global-lookup-cache when a function contains no
  LOAD_GLOBAL

inlining discussion
--------------------

- need to trace aggressively
- give up when trace becomes too long
- need to remember when we gave up
- need to reset counters
- tracing aggressively will put pressure on the speed of tracing
- what should we do about recursive calls?
- connecting compiled loops accross a call?
- problem: when we inline one function, and then hit something non-inlinable,
  how do we make the inlined function's frame not escape via the
  non-inlinable's f_back?

things we know are missing
---------------------------

metainterp/frontend:
- virtualizables are not finished:
  fix 'test_external_read_sometimes'

- float support

- speed of tracing and fallbacks?
- save space on all the guard operations (see resume.py)

backend:
- speed of backend?

- support threads again!

Python interpreter:
- lookups of various kinds
- calls

tests:
- find a test for r64742 (JitException capture)

Goals/Benchmarks
-----------------

Goal: be somehow faster than CPython in real programs

Benchmarks:
    - Richards
    - Pystone
    - mako, gadfly, templess
    - port some of the JS benchmarks?
    - look at unladden-swallow benchmarks
    - Sympy
    - Simpy?
    - Pyrolog
    
later:
    - translate.py

- there should be a unified way to run these benchmark
- benchmarks should be run nightly
- we might need a benchmarking server


ootype discussion
------------------

- try to unify interfaces to make doing the right thing for ootype easier
- different constraints for different groups of people
- what to do with ootype jit support after Anto finished his PhD?
