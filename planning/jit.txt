TASKS
-----

- inlining on the Python level (see discussion)
- streamline calls
- stability!

- improve test running, compile only once

- sort out a benchmark infrastructure. graphs!!! (iko is going to do
   some sorting)

- nightly run of checks on output of pypy-c-jit: we need tests for
  pypy-jit behaviour that explicitely check whether the loops make
  sense

- objectmodel.instantiate is currently not seen by the JIT. This makes all
  instance allocation in the Python interpreter escape

- store sinking also for get/setarrayitem
- lose less information across residual calls

- the tragedy of the skipped tests
- keep test coverage in check

- think about code memory management

- compare backend vs gcc quality

- jit/asmgcc + threads?

- jit should inline the fast path of mallocs

- update things in metainterp/doc

Python interpreter:
- make shared dicts support shadowtracking
- don't look for the global-lookup-cache when a function contains no
  LOAD_GLOBAL
- it's a bit silly that it's possible to change the code objects of builtin
  functions
- raising an exception tends to escape frames, due to the traceback capturing

inlining discussion
--------------------

- need to remember when we gave up
- tracing aggressively will put pressure on the speed of tracing
- what should we do about recursive calls?
- connecting compiled loops accross a call?

things we know are missing
---------------------------

metainterp/frontend:
- virtualizables are not finished:
  fix 'test_external_read_sometimes'

- float support

- save space on all the guard operations (see resume.py)

backend:
- speed of backend?

Python interpreter:
- lookups of various kinds
- calls

tests:
- find a test for r64742 (JitException capture)

Goals/Benchmarks
-----------------

Goal: be somehow faster than CPython in real programs

Benchmarks:
    - Richards
    - Pystone
    - mako, gadfly, templess
    - port some of the JS benchmarks?
    - look at unladden-swallow benchmarks
    - Sympy
    - Simpy?
    - Pyrolog
    
later:
    - translate.py

- there should be a unified way to run these benchmark
- benchmarks should be run nightly
- we might need a benchmarking server


ootype discussion
------------------

- try to unify interfaces to make doing the right thing for ootype easier
- different constraints for different groups of people
- what to do with ootype jit support after Anto finished his PhD?
