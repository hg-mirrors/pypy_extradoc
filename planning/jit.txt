TASKS
-----

- sort out a benchmark infrastructure. graphs!

- jit/asmgcc + threads? [DONE probably.  Needs a bit more testing.]

- think about code memory management

- forcing virtualizables should only force fields affected, not everything

- compress resume data (?)

- think out looking into functions or not, based on arguments,
  for example contains__Tuple should be unrolled if tuple is of constant
  length

- look at example of storing small strings in large lists (any sane templating
  engine would do it) and not spend all the time in
  _trace_and_drag_out_of_nursery

- improve tracing/blackholing speed (?)

- some guards will always fail if they ever start failing
  (e.g. the class version tag).  Do something more clever about it.


Python interpreter:

- goal: on average <=5 guards per original bytecode

- prevent jitting really general */** calls

- put the class into the structure to get only one promote when using an
  instance

- look into failing pypy-c-jit apptests, pypy-c-jit translate.py

- improve ''.join and u''.join by using stringbuilder, enable realloc
  for hybrid GC (on stringbuilder branch so far).



JIT-related Release Tasks
---------------------------

(there are other release tasks, specifically about packaging, documentation,
website and stability that need sorting out too. However, they are beyond the
scope of this section)

consideration: if we plan to ship binaries the threads+JIT combination need to have a reasonable story (too confusing to pick one or the other)

wishlist:
- improve on predictability: don't trace into signals ... but produce just a
  conditional call (or just abort the trace)
- directly call assembler for residual portal calls
- maybe think again about the recursion limit checking, which slows down calls
  quite a bit
- since threads are enabled with the JIT, getexecutioncontext cannot be folded
  by the JIT anymore. we need to do something in that direction

known bugs:
- the trace-hook is not correctly called while blackholing, see
  test_pyframe.py:AppTestJitTraceInteraction



META
-----

- stability!

- keep test coverage in check

- prevent too much method and fields demoting in the jit

- the tragedy of the skipped tests

- update things in metainterp/doc

inlining discussion
--------------------

- at some point we need to merge the tails of loops, to avoid exponential
  explosion
- tracing aggressively will put pressure on the speed of tracing
- what should we do about recursive calls?
- connecting compiled loops accross a call?


things we know are missing
---------------------------

backend:
- speed of backend?

Python interpreter:
- lookups of various kinds
- calls

tests:
- find a test for r64742 (JitException capture)

Goals/Benchmarks
-----------------

Goal: be somehow faster than CPython in real programs

Benchmarks:
    - Richards
    - Pystone
    - mako, gadfly, templess
    - port some of the JS benchmarks?
    - look at unladden-swallow benchmarks
    - Sympy
    - Simpy?
    - Pyrolog
    
later:
    - translate.py

- there should be a unified way to run these benchmark
- benchmarks should be run nightly
- we might need a benchmarking server


ootype discussion
------------------

- try to unify interfaces to make doing the right thing for ootype easier
- different constraints for different groups of people
- what to do with ootype jit support after Anto finished his PhD?


memory usage
------------

- we use too much memory during jitting.  Notably of the following
  types (in decreasing order of total size, for Pystone):
    - rpy_string
    - GcArray of AbstractValue (unknown if fixedsize or not)
    - DoneWithThisFrameRef
    - dict {AbstractValue: SHORT}
    - GcArray of ResOperation
    - resizable list of AbstractValue
    - ResOperation
    - ResumeGuardDescr
    - ConstInt


Plan for killing the hacks in executioncontext.py
-------------------------------------------------

1. Finish support for virtualizables.  We need a way to ask,
   typically from a recursive residual call, for the structure
   in some parent JITted context.  So the virtualizable and
   all virtuals need a way to be forced.  The idea is to reuse
   as much as possible the backend logic of guard failure and
   the corresponding frontend logic to rebuild virtuals, but
   called in this case indirectly, in the middle of running a
   residual call.

2. Reverting to the old logic without "f_forward", we need to
   make "f_back" and "topframe" pointers that can reference
   virtuals.  Probably implemented by having them point to a
   stub object that contains the stack position and the index
   of the virtual in the list of virtuals.  If we need to
   access its content, we force it as above.  For this to work,
   we must make sure that no reference to such a stub can live
   longer than the residual call -- either we are sure that it
   dies, or we have forced it.

Open question: how can this be done on CLI?
