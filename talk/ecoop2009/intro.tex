\section{Introduction}

Dynamic languages are increasingly popular etc. etc.

The easiest way to implement a dynamic language such as Python is to write an
interpreter; however, interpreters are slow.

The alternative is to write a compiler; writing a compiler that targets a high
level virtual machine like CLI or JVM is easier than targeting a real CPU, but
it still require a lot of work, as IronPython, Jython, JRuby demonstrate.

Moreover, writing a static compiler is often not enough to get high
performance; IronPython and JRuby are going in the direction of JIT compiling
specialized versions of the code depending on the actual values/types seen at
runtime; this approach seems to work, but writing it manually requires an
enormous effort.

\cfbolz{we should cite the dyla paper somewhere here. also, we generally need
more references}

PyPy's approach is to automatize the generation of JIT compilers in order
to reduce to a minimum the effort required to get a fast implementation of a
dynamic language; all you have to do is to write a high level specification of
the language (by writing an interpreter), and putting it through PyPy's
translation toolchain. The automatic generation of JIT compilers is done with
the help of partial evaluation techniques.

The contributions of this paper are \emph{promotion}, a generalization of
polymorphic inline caches that make partial evaluation practical for dynamic
languages and trying out the idea of JIT-layering XXX.

\subsection{PyPy and RPython}

\anto{as Armin points out, the two CLI backends can be easily confused; what
  about renaming the ``CLI Backend for flowgraphs'' into ``CLI bytecode
  compiler''? Any better idea for the name?}

\begin{figure}[h]
\begin{center}
\includegraphics[width=.6\textwidth]{diagram0}
\caption{PyPy infrastracture for generating an interpreter of a
  language $L$ for several platforms}\label{pypy-fig}
\end{center}
\end{figure}

The \emph{PyPy} project\footnote{\texttt{http://codespeak.net/pypy/}}
\cite{RigoPedroni06} was initially conceived to develop an implementation of Python which
could be easily portable and extensible without renouncing efficiency.
To achieve these aims, the PyPy implementation is based on a highly
modular design which allows high-level aspects
to be separated from lower-level implementation details.
The abstract semantics of Python is defined by an interpreter written
in a high-level language, called RPython \cite{AACM-DLS07}, which is in fact a subset of
Python where some dynamic features have been sacrificed to allow an
efficient translation of the interpreter to low-level code.

Compilation of the interpreter is implemented as a stepwise
refinement by means of a translation toolchain which performs type
analysis, code optimizations and several transformations aiming at 
incrementally providing implementation details such as memory management or the threading model.
The different kinds of intermediate codes  which are refined 
during the translation process are all represented by a collection of control flow graphs,
at several levels of abstractions.

Finally, the low-level control flow-graphs produced by the toolchain
can be translated to executable code for a specific platform by a
corresponding backend.
Currently, three fully developed backends are available to produce
executable C/POSIX code, Java and CLI/.NET bytecode. 

Despite having been specifically developed for Python, the PyPy infrastructure
can in fact be used for implementing other languages. Indeed, there were
successful experiments of using PyPy to implement several other languages such
as Smalltalk \cite{BolzEtAl08}, JavaScript, Scheme and Prolog.
As suggested by Figure~\ref{pypy-fig}, a portable interpreter for a
generic language $L$  can be
easily developed once an interpreter for $L$ has been implemented in
RPython.

\subsection{PyPy and JIT-Generation}

This section will give a high-level overview of how the JIT-generation process
works. More details will be given in subsequent sections.

- write an interpreter
- add some hints to the interpreter

translation time:
- start the translation process, flow graphs
- run a binding-time analysis using the hints, to figure out ...
- turn the flow graphs into rainbow bytecode
- turn the flow graphs of the rainbow interpreter and the original flow graphs
into .NET code

runtime:
when the interpreter is started and a function should be interpreted:
 - the generated JIT starts compiling the function 
 - it produces .NET bytecode until it does not have enough information to
 continue. then it stops the compilation and puts a callback into the compiler
 into the generated bytecode.
 - at this point the .NET bytecode that is produced so far is executed.
 - when the callback into the compiler is hit, execution stops and compilation
 starts again
 - afterwards execution continues after the callback (running the code that was
 newly produced)


