\section{Introduction}
Implementing a dynamic language such as Python with a compiler rather than with an interpreter improves performances at the cost of
an increasing complexity. Furthermore, generating code for high level virtual machines like CLI or JVM enhances portability and inter-operability.

Writing a compiler that targets a high CLI or JVM is easier than targeting a real CPU, but
it still requires a lot of work, as
IronPython\footnote{http://www.codeplex.com/IronPython},
Jython\footnote{http://www.jython.org/}
and JRuby\footnote{http://jruby.codehaus.org/} demonstrate.

Moreover, writing a static compiler is often not enough to get high
performance.  IronPython and JRuby are going in the direction of
compiling just-in-time (JIT) specialized versions of the code depending
on the actual values/types seen at runtime; this approach seems to work,
but writing it manually requires an enormous effort.

PyPy's approach \cite{RiBo07_223} is to automatize the generation of 
specializing JIT compilers in order
to minimize the effort required to get a fast implementation of a
dynamic language; automatic generation of JIT compilers is done with
the help of partial evaluation techniques and requires the user only
to provide an interpreter with some manual annotations which hint
the generator how interpretation and JIT compilation has to be interleaved \cite{PyPyJIT09}.

More precisely, in this paper we focus on the ability of generating a JIT compiler able to emit code
for the .NET virtual machine. To our knowledge, this is the first experiment with an interpreter with
two \emph{layers} of JIT compilation, since, before being executed, the
emitted code is eventually compiled again by .NET's own JIT compiler.

The main contribution of this paper is to demonstrate that the idea of
\emph{JIT layering} can give good results, as dynamic languages can be even
faster than their static counterparts.

\anto{XXX: we first say that IronPython\&co. does JIT compilation, then we say
  we are the first to do JIT layering.  This seems a bit strange, though at
  the moment I can't think of any better way to word this concept}

\subsection{Overview of PyPy}

The \emph{PyPy} project\footnote{\texttt{http://codespeak.net/pypy/}}
\cite{RigoPedroni06} was initially conceived to develop an implementation of Python which
could be easily portable and extensible without renouncing efficiency.
To achieve these aims, the PyPy implementation is based on a highly
modular design which allows high-level aspects
to be separated from lower-level implementation details.
The abstract semantics of Python is defined by an interpreter written
in a high-level language, called RPython \cite{AACM-DLS07}, which is in fact a subset of
Python where some dynamic features have been sacrificed to allow an
efficient translation of the interpreter to low-level code.

Compilation of the interpreter is implemented as a stepwise
refinement by means of a translation toolchain which performs type
analysis, code optimizations and several transformations aiming at 
incrementally providing implementation details such as memory management or the threading model.
The different kinds of intermediate codes  which are refined 
during the translation process are all represented by a collection of control flow graphs,
at several levels of abstractions.

Finally, the low-level control flow graphs produced by the toolchain
can be translated to executable code for a specific platform by a
corresponding backend.
Currently, three fully developed backends are available to produce
executable C/POSIX code, Java and CLI/.NET bytecode. 

Despite having been specifically developed for Python, the PyPy infrastructure
can in fact be used for implementing other languages. Indeed, there were
successful experiments of using PyPy to implement several other languages such
as Smalltalk \cite{BolzEtAl08}, JavaScript, Scheme and Prolog.

\commentout{
As suggested by Figure~\ref{pypy-fig}, a portable interpreter for a
generic language $L$  can be
easily developed once an interpreter for $L$ has been implemented in
RPython.
}

\subsection{PyPy and JIT-Generation}
\label{sec:jitgen}

One of the most important aspects that PyPy's translation toolchain can weave
in is the \emph{automatic generation of a JIT compiler}.  This section will
give a high-level overview of how the JIT-generation process works. More
details can be found in \cite{PyPyJIT} and \cite{PyPyJIT09}.

The main difference between the JIT compilers generated by PyPy and the
ones found in other projects like IronPython is that the latter compile
code at the method granularity -- if on the one hand they can exploit
some of the knowledge gathered at runtime (e.g.\ the types of method
parameters), on the other hand they can do little to optimize most of
the operations inside, because few assumptions can be made about the
global state of the program.  The PyPy JITs, on the other hand, work at
a sub-method granularity, as described next.

When using PyPy, the first step is to write an interpreter for the chosen language.  Since it
must be fed to the translation toolchain, the interpreter has to be written in
RPython.  Then, to guide the process, we need to add few manual
annotations to the interpreter, in order to teach the JIT generator which
information is important to know at compile-time.  Annotations are inserted
as \emph{hints}, as described in section \ref{sec:hints}.
From these hints, PyPy will statically generate an interpreter and a JIT
compiler in a single executable (here a .NET executable).

\anto{maybe we can avoid to talk about hints?}

\commentout{
It is important to distinguish between three distinct phases of execution:

\begin{enumerate}
\item \textbf{Translation-time}: when the translation toolchain runs and the
  JIT compiler is automatically generated from the interpreter.  The result is
  an executable that can be used to run programs written in the chosen
  language.
\item \textbf{Compile-time}: when the JIT compiler runs, generating executable
  code on the fly.
\item \textbf{Runtime}: when the code generated at compile-time is executed.
\end{enumerate}

Note that in this schema translation-time happens only once, on the
developer's machine.  By contrast, compile-time and runtime happens every time
the user wants to run some program.
}

\commentout{
By emitting code at runtime, JIT compilers can exploit extra
knowledge compared to traditional static compilers -- more than just the
type of the function arguments.  However, special care is needed to
choose a strategy for JIT compilation that lets the compiler take the
best of this advantage.
}

The interesting property of the generated JIT compiler is to delay the
compilation until it knows all the information needed to generate
efficient code.  In other words, at runtime, when the interpreter notice
that it is useful to compile a given piece of code, it sends it to the
JIT compiler; however, if at some point the JIT compiler does not know
about something it needs, it generates a callback into itself and stops
execution.

Later, when the generated code is executed, the callback might be hit and the JIT
compiler is restarted again.  At this point, the JIT knows exactly the state
of the program and can exploit all this extra knowledge to generate highly
efficient code.  Finally, the old code is patched and linked to the newly
generated code, so that the next time the JIT compiler will not be invoked
again.  As a result, \textbf{runtime and compile-time are continuously
interleaved}. 

Implementing such a behavior requires a tight coupling between compile-time
and run-time: a \emph{callback} is put in the generated code, which can invoke
the compiler again.  When the callback is actually reached at run-time, and
only then, the compiler resumes and uses the knowledge of the actual run-time
value to generate more code.

The new generated code is potentially different for each run-time value seen.
This implies that the generated code needs to contain some sort of updatable
switch, or \emph{flexswitch}, which can pick the right code path based on the
run-time value.  Typically, the value we switch on is the runtime dynamic type
of a value, so that the JIT compiler has all information needed to produce
very good code for that specific case.

\commentout{
The primitive to do this sort of interleaving is called promotion,
it is described in Section \ref{sec:promotion}.

One of the most important optimizations that the generated JIT does is removing
unnecessary allocations. This is described in Section \ref{sec:virtuals}
}

Modifying the old code to link to the newly generated one is very challenging on
.NET, as the framework does not offer any primitive to do this.  Section
\ref{sec:clibackend} explains how it is possible to simulate this behaviour.

\anto{XXX: mention virtuals/escape analysis?}
